// BiDS

@misc{union_proceedings_2019,
	type = {Website},
	title = {Proceedings of 2019 {Big} {Data} from {Space} ({BiDS}'19) : 19-21 {February} 2019, {Munich} ({Germany}).},
	shorttitle = {Proceedings of 2019 {Big} {Data} from {Space} ({BiDS}'19)},
	url = {https://publications.europa.eu/en/publication-detail/-/publication/7075ed48-3a4d-11e9-8d04-01aa75ed71a1/language-en},
	abstract = {Big Data from Space refers to the massive spatio-temporal Earth and Space observation data collected by a variety of sensors - ranging from ground based to space-borne - and the synergy with data coming from other sources and communities. This domain is currently facing sharp development with numerous new initiatives and breakthroughs from intelligent sensors' networks to data science application. These developments are empowering new approaches and applications in various and diverse domains influencing life on earth and societal aspects, from sensing cities, monitoring human settlements and urban areas to climate change and security. The goal of the Big Data from Space conference is to bring together researchers, engineers, developers, and users in the area of Big Data from Space. It is co-organised by ESA, the Joint Research Centre (JRC) of the European Commission, and the European Union Satellite Centre (SatCen). The 2019 edition of the conference was hosted by the German Aerospace Center (DLR) and held in the Alte Kongresshalle of Munich (Germany) from the 19th to the 21st of February 2019. These proceedings consist of a collection of 75 short papers accepted for oral or poster presentation at the conference as a result of the peer-review process by the conference programme committee. The papers are lined up around the topics matching the oral sessions as well as the poster session, also organised by topics. These contributions provide a snapshot of the current research activities, developments, and initiatives in Big Data from Space. This 4th edition of the Big Data from Space conference is directed towards 'Turning Data into Insights'. Indeed, while the first editions of the conference concentrated on technologies and platforms capable of sustaining the sharp increase of data streams originating from space sensors, the development of efficient and effective methodologies and algorithms capable of extracting insights from these data is gradually becoming the main challenge. In this context, artificial intelligence and machine learning techniques have started to play a key role as illustrated by numerous papers of this conference edition. Methodological developments are motivated by the pressing need to extract information on large areas and/or over long time series to better understand the dynamics of the processes that are shaping our planet and indeed our universe in the case of data collected by telescopes. The topic of analysis ready data has also emerged since the last edition and is closely linked with the development of new data cube representations. Big data from space is also introducing some new legal challenges and the need for further developments of standards and interoperable interfaces between the growing number of platforms hosting multi-petabyte scale data co-located with processing capabilities. All these topics as well as other generic key aspects of big data are mirrored in dedicated sections of these proceedings.},
	language = {en},
	urldate = {2019-06-13},
	author = {Union, Publications Office of the European},
	month = feb,
	year = {2019},
	file = {Snapshot:/home/hbo/Zotero/storage/AYVYQABJ/language-en.html:text/html}
}

@inproceedings{moumtzidou_road_2019,
	title = {{Road} {Passability} {Estimation} {Using} {Deep} {Neural} {Networks} {and} {Satellite} {Image} {Patches}},
	doi = {10.5281/zenodo.2450333},
	abstract = {Artificial Intelligence (AI) technologies are getting deeper and deeper into remote sensing and satellite image processing offering value-added products and services in a real-time manner. Deep learning techniques applied on visual content are able to infer accurate decisions about concepts and events in an automatic way, based on Deep Convolutional Neural Networks which are trained on very large external image collections in order to transfer knowledge from them to the considered task. Existing emergency management services focus on the detection of flooded areas, without the possibility to infer if a road from point A to a point B is passable or not. To that end, we propose an automatic road passability service that is able to deliver the parts of the road network which are not passable, using satellite image patches. Experiments and fine-tuning on an annotated benchmark collection indicates the most suitable model among several Deep Convolutional Neural Networks.},
	author = {Moumtzidou, Anastasia and Bakratsas, Marios and Andreadis, Stelios and Gialampoukidis, Ilias and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
	month = feb,
	year = {2019},
	file = {Full Text PDF:/home/hbo/Zotero/storage/9G2NJ44U/Moumtzidou et al. - 2019 - ROAD PASSABILITY ESTIMATION USING DEEP NEURAL NETW.pdf:application/pdf}
}

@article{zhang_multi-source_2010,
	title = {Multi-source remote sensing data fusion: status and trends},
	volume = {1},
	issn = {1947-9832},
	shorttitle = {Multi-source remote sensing data fusion},
	url = {https://doi.org/10.1080/19479830903561035},
	doi = {10.1080/19479830903561035},
	abstract = {With the fast development of remote sensor technologies, e.g. the appearance of Very High Resolution (VHR) optical sensors, SAR, LiDAR, etc., mounted on either airborne or spaceborne platforms, multi-source remote sensing data fusion techniques are emerging due to the demand for new methods and algorithms. The general fusion techniques have been well developed and applied in various fields ranging from satellite earth observation to computer vision, medical image processing, defence security and so on. Despite the fast development, the techniques remain challenging for multi-source data fusion within varying spatial and temporal resolutions. This article reviews current techniques of multi-source remote sensing data fusion and discusses their future trends and challenges through the concept of hierarchical classification, i.e., pixel/data level, feature level and decision level. This article concentrates on discussing optical panchromatic and multi-spectral data fusing methods. So far, the pixel level fusion methods have mainly focused on optical data fusion; high-level fusion includes feature level and decision level fusion of multi-source data, such as synthetic aperture radar, optical images, LiDAR and other types of data. Finally, this article summarises several trends tending to broaden the application of multi-source data fusion.},
	number = {1},
	urldate = {2019-06-13},
	journal = {International Journal of Image and Data Fusion},
	author = {Zhang, Jixian},
	month = mar,
	year = {2010},
	keywords = {data fusion, LiDAR, multi-source remote sensing data, SAR},
	pages = {5--24},
	file = {Full Text PDF:/home/hbo/Zotero/storage/DMZRJ8PW/Zhang - 2010 - Multi-source remote sensing data fusion status an.pdf:application/pdf;Snapshot:/home/hbo/Zotero/storage/7Y2NQ5EJ/19479830903561035.html:text/html}
}

@article{zhu_deep_2017,
	title = {Deep {Learning} in {Remote} {Sensing}: {A} {Comprehensive} {Review} and {List} of {Resources}},
	volume = {5},
	issn = {2168-6831},
	shorttitle = {Deep {Learning} in {Remote} {Sensing}},
	doi = {10.1109/MGRS.2017.2762307},
	abstract = {Central to the looming paradigm shift toward data-intensive science, machine-learning techniques are becoming increasingly important. In particular, deep learning has proven to be both a major breakthrough and an extremely powerful tool in many fields. Shall we embrace deep learning as the key to everything? Or should we resist a black-box solution? These are controversial issues within the remote-sensing community. In this article, we analyze the challenges of using deep learning for remote-sensing data analysis, review recent advances, and provide resources we hope will make deep learning in remote sensing seem ridiculously simple. More importantly, we encourage remote-sensing scientists to bring their expertise into deep learning and use it as an implicit general model to tackle unprecedented, large-scale, influential challenges, such as climate change and urbanization.},
	number = {4},
	journal = {IEEE Geoscience and Remote Sensing Magazine},
	author = {Zhu, X. X. and Tuia, D. and Mou, L. and Xia, G. and Zhang, L. and Xu, F. and Fraundorfer, F.},
	month = dec,
	year = {2017},
	keywords = {climate change, Computer vision, data-intensive science, Feature extraction, Hyperspectral imaging, looming paradigm shift, Machine learning, machine-learning techniques, remote sensing, Remote sensing, remote-sensing data analysis, Tutorials},
	pages = {8--36},
	file = {Full Text:/home/hbo/Zotero/storage/FJFE555F/Zhu et al. - 2017 - Deep Learning in Remote Sensing A Comprehensive R.pdf:application/pdf;IEEE Xplore Abstract Record:/home/hbo/Zotero/storage/TBQIRFIP/8113128.html:text/html}
}

@misc{bids,
	title = {{Big Data from Space} 2019},
	howpublished = "https://www.bigdatafromspace2019.org",
	year = {2019},
  note = "[Online; accessed 14 June 2019]"
}
